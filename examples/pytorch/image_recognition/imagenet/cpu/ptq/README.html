

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Step-by-Step &mdash; Intel® Low Precision Optimization Tool  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../../" src="../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../../index.html" class="icon icon-home"> Intel® Low Precision Optimization Tool
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../welcome.html">Introduction to Intel LPOT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../docs/introduction.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../docs/doclist.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../CONTRIBUTING.html">Contributing Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../SECURITY.html">Security Policy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">Intel® Low Precision Optimization Tool</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Step-by-Step</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../../../_sources/examples/pytorch/image_recognition/imagenet/cpu/ptq/README.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="step-by-step">
<h1>Step-by-Step<a class="headerlink" href="#step-by-step" title="Permalink to this headline">¶</a></h1>
<p>This document describes the step-by-step instructions for reproducing PyTorch ResNet50/ResNet18/ResNet101 tuning results with Intel® Low Precision Optimization Tool(LPOT).</p>
<blockquote>
<div><p><strong>Note</strong></p>
<ul class="simple">
<li><p>PyTorch quantization implementation in imperative path has limitation on automatically execution. It requires to manually add QuantStub and DequantStub for quantizable ops, it also requires to manually do fusion operation.</p></li>
<li><p>LPOT supposes user have done these two steps before invoking LPOT interface.
For details, please refer to https://pytorch.org/docs/stable/quantization.html</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="prerequisite">
<h1>Prerequisite<a class="headerlink" href="#prerequisite" title="Permalink to this headline">¶</a></h1>
<div class="section" id="installation">
<h2>1. Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install -r requirements.txt
</pre></div>
</div>
</div>
<div class="section" id="prepare-dataset">
<h2>2. Prepare Dataset<a class="headerlink" href="#prepare-dataset" title="Permalink to this headline">¶</a></h2>
<p>Download <a class="reference external" href="http://www.image-net.org/">ImageNet</a> Raw image to dir: /path/to/imagenet.  The dir include below folder:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ls /path/to/imagenet
train  val
</pre></div>
</div>
</div>
</div>
<div class="section" id="run">
<h1>Run<a class="headerlink" href="#run" title="Permalink to this headline">¶</a></h1>
<div class="section" id="resnet50">
<h2>1. ResNet50<a class="headerlink" href="#resnet50" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/pytorch/image_recognition/imagenet/cpu/ptq
python main.py -t -a resnet50 --pretrained /path/to/imagenet
</pre></div>
</div>
</div>
<div class="section" id="resnet18">
<h2>2. ResNet18<a class="headerlink" href="#resnet18" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/pytorch/image_recognition/imagenet/cpu/ptq
python main.py -t -a resnet18 --pretrained /path/to/imagenet
</pre></div>
</div>
</div>
<div class="section" id="resnext101-32x8d">
<h2>3. ResNext101_32x8d<a class="headerlink" href="#resnext101-32x8d" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/pytorch/image_recognition/imagenet/cpu/ptq
python main.py -t -a resnext101_32x8d --pretrained /path/to/imagenet
</pre></div>
</div>
</div>
<div class="section" id="inceptionv3">
<h2>4. InceptionV3<a class="headerlink" href="#inceptionv3" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/pytorch/image_recognition/imagenet/cpu/ptq
python main.py -t -a inception_v3 --pretrained /path/to/imagenet
</pre></div>
</div>
</div>
<div class="section" id="mobilenet-v2">
<h2>5. Mobilenet_v2<a class="headerlink" href="#mobilenet-v2" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/pytorch/image_recognition/imagenet/cpu/ptq
python main.py -t -a mobilenet_v2 --pretrained /path/to/imagenet
</pre></div>
</div>
</div>
<div class="section" id="resnet50-dump-tensors-for-debug">
<h2>6. ResNet50 dump tensors for debug<a class="headerlink" href="#resnet50-dump-tensors-for-debug" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>  <span class="nb">cd</span> examples/pytorch/image_recognition/imagenet/cpu/ptq
  python main_dump_tensors.py -t -a resnet50 --pretrained /path/to/imagenet
</pre></div>
</div>
</div>
<div class="section" id="resnet50-with-intel-pytorch-extension">
<h2>7. ResNet50 With Intel PyTorch Extension<a class="headerlink" href="#resnet50-with-intel-pytorch-extension" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>  <span class="nb">cd</span> examples/pytorch/image_recognition/imagenet/cpu/PTQ
  python main.py -t -a resnet50 -j <span class="m">0</span> --pretrained --ipex /path/to/imagenet
</pre></div>
</div>
</div>
</div>
<div class="section" id="saving-and-loading-model">
<h1>Saving and loading model:<a class="headerlink" href="#saving-and-loading-model" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Saving model:
After tuning with LPOT, we can get LPOT.model:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="k">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">(</span><span class="s2">&quot;./conf.yaml&quot;</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">lpot_model</span> <span class="o">=</span> <span class="n">quantizer</span><span class="p">()</span>
</pre></div>
</div>
<p>Here, lpot_model is LPOT model class, so it has “save” API:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lpot_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;Path_to_save_configure_file&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>loading model:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Without IPEX</span>
<span class="n">model</span>                 <span class="c1"># fp32 model</span>
<span class="kn">from</span> <span class="nn">lpot.utils.pytorch</span> <span class="kn">import</span> <span class="n">load</span>
<span class="n">quantized_model</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">Path</span><span class="p">,</span> <span class="s1">&#39;best_configure.yaml&#39;</span><span class="p">),</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">Path</span><span class="p">,</span> <span class="s1">&#39;best_model_weights.pt&#39;</span><span class="p">),</span> <span class="n">model</span><span class="p">)</span>

<span class="c1"># With IPEX</span>
<span class="kn">import</span> <span class="nn">intel_pytorch_extension</span> <span class="kn">as</span> <span class="nn">ipex</span> 
<span class="n">model</span>                 <span class="c1"># fp32 model</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ipex</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">new_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">new_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ipex</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">))</span>
<span class="n">ipex_config_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">tuned_checkpoint</span><span class="p">),</span>
                                <span class="s2">&quot;best_configure.json&quot;</span><span class="p">)</span>
<span class="n">conf</span> <span class="o">=</span> <span class="n">ipex</span><span class="o">.</span><span class="n">AmpConf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">,</span> <span class="n">configure_file</span><span class="o">=</span><span class="n">ipex_config_path</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">ipex</span><span class="o">.</span><span class="n">AutoMixPrecision</span><span class="p">(</span><span class="n">conf</span><span class="p">,</span> <span class="n">running_mode</span><span class="o">=</span><span class="s1">&#39;inference&#39;</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">new_model</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ipex</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">))</span>
</pre></div>
</div>
<p>Please refer to <a class="reference external" href="./main.py">Sample code</a>.</p>
</div>
<div class="section" id="examples-of-enabling-lpot-auto-tuning-on-pytorch-resnet">
<h1>Examples of enabling LPOT auto tuning on PyTorch ResNet<a class="headerlink" href="#examples-of-enabling-lpot-auto-tuning-on-pytorch-resnet" title="Permalink to this headline">¶</a></h1>
<p>This is a tutorial of how to enable a PyTorch classification model with LPOT.</p>
</div>
<div class="section" id="user-code-analysis">
<h1>User Code Analysis<a class="headerlink" href="#user-code-analysis" title="Permalink to this headline">¶</a></h1>
<p>LPOT supports three usages:</p>
<ol class="simple">
<li><p>User only provide fp32 “model”, and configure calibration dataset, evaluation dataset and metric in model-specific yaml config file.</p></li>
<li><p>User provide fp32 “model”, calibration dataset “q_dataloader” and evaluation dataset “eval_dataloader”, and configure metric in tuning.metric field of model-specific yaml config file.</p></li>
<li><p>User specifies fp32 “model”, calibration dataset “q_dataloader” and a custom “eval_func” which encapsulates the evaluation dataset and metric by itself.</p></li>
</ol>
<p>As ResNet18/50/101 series are typical classification models, use Top-K as metric which is built-in supported by LPOT. So here we integrate PyTorch ResNet with LPOT by the first use case for simplicity.</p>
<div class="section" id="write-yaml-config-file">
<h2>Write Yaml Config File<a class="headerlink" href="#write-yaml-config-file" title="Permalink to this headline">¶</a></h2>
<p>In examples directory, there is a template.yaml. We could remove most of items and only keep mandotory item for tuning.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">imagenet_ptq</span>
  <span class="nt">framework</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pytorch</span>

<span class="nt">quantization</span><span class="p">:</span>
  <span class="nt">calibration</span><span class="p">:</span>
    <span class="nt">sampling_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">300</span>
    <span class="nt">dataloader</span><span class="p">:</span>
      <span class="nt">dataset</span><span class="p">:</span>
        <span class="nt">ImageFolder</span><span class="p">:</span>
          <span class="nt">root</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/path/to/calibration/dataset</span>
      <span class="nt">transform</span><span class="p">:</span>
        <span class="nt">RandomResizedCrop</span><span class="p">:</span>
          <span class="nt">size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">224</span>
        <span class="nt">RandomHorizontalFlip</span><span class="p">:</span>
        <span class="nt">ToTensor</span><span class="p">:</span>
        <span class="nt">Normalize</span><span class="p">:</span>
          <span class="nt">mean</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.485</span><span class="p p-Indicator">,</span> <span class="nv">0.456</span><span class="p p-Indicator">,</span> <span class="nv">0.406</span><span class="p p-Indicator">]</span>
          <span class="nt">std</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.229</span><span class="p p-Indicator">,</span> <span class="nv">0.224</span><span class="p p-Indicator">,</span> <span class="nv">0.225</span><span class="p p-Indicator">]</span>

<span class="nt">evaluation</span><span class="p">:</span>
  <span class="nt">accuracy</span><span class="p">:</span>
    <span class="nt">metric</span><span class="p">:</span>
      <span class="nt">topk</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">dataloader</span><span class="p">:</span>
      <span class="nt">batch_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">30</span>
      <span class="nt">dataset</span><span class="p">:</span>
        <span class="nt">ImageFolder</span><span class="p">:</span>
          <span class="nt">root</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/path/to/evaluation/dataset</span>
      <span class="nt">transform</span><span class="p">:</span>
        <span class="nt">Resize</span><span class="p">:</span>
          <span class="nt">size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
        <span class="nt">CenterCrop</span><span class="p">:</span>
          <span class="nt">size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">224</span>
        <span class="nt">ToTensor</span><span class="p">:</span>
        <span class="nt">Normalize</span><span class="p">:</span>
          <span class="nt">mean</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.485</span><span class="p p-Indicator">,</span> <span class="nv">0.456</span><span class="p p-Indicator">,</span> <span class="nv">0.406</span><span class="p p-Indicator">]</span>
          <span class="nt">std</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.229</span><span class="p p-Indicator">,</span> <span class="nv">0.224</span><span class="p p-Indicator">,</span> <span class="nv">0.225</span><span class="p p-Indicator">]</span>
  <span class="nt">performance</span><span class="p">:</span>
    <span class="nt">configs</span><span class="p">:</span>
      <span class="nt">cores_per_instance</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
      <span class="nt">num_of_instance</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">7</span>
    <span class="nt">dataloader</span><span class="p">:</span>
      <span class="nt">batch_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
      <span class="nt">dataset</span><span class="p">:</span>
        <span class="nt">ImageFolder</span><span class="p">:</span>
          <span class="nt">root</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/path/to/evaluation/dataset</span>
      <span class="nt">transform</span><span class="p">:</span>
        <span class="nt">Resize</span><span class="p">:</span>
          <span class="nt">size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
        <span class="nt">CenterCrop</span><span class="p">:</span>
          <span class="nt">size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">224</span>
        <span class="nt">ToTensor</span><span class="p">:</span>
        <span class="nt">Normalize</span><span class="p">:</span>
          <span class="nt">mean</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.485</span><span class="p p-Indicator">,</span> <span class="nv">0.456</span><span class="p p-Indicator">,</span> <span class="nv">0.406</span><span class="p p-Indicator">]</span>
          <span class="nt">std</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.229</span><span class="p p-Indicator">,</span> <span class="nv">0.224</span><span class="p p-Indicator">,</span> <span class="nv">0.225</span><span class="p p-Indicator">]</span>

<span class="nt">tuning</span><span class="p">:</span>
  <span class="nt">accuracy_criterion</span><span class="p">:</span>
    <span class="nt">relative</span><span class="p">:</span>  <span class="l l-Scalar l-Scalar-Plain">0.01</span>
  <span class="nt">exit_policy</span><span class="p">:</span>
    <span class="nt">timeout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
  <span class="nt">random_seed</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">9527</span>
</pre></div>
</div>
<p>Here we choose topk built-in metric and set accuracy target as tolerating 0.01 relative accuracy loss of baseline. The default tuning strategy is basic strategy. The timeout 0 means unlimited time for a tuning config meet accuracy target.</p>
</div>
<div class="section" id="prepare">
<h2>Prepare<a class="headerlink" href="#prepare" title="Permalink to this headline">¶</a></h2>
<p>PyTorch quantization requires two manual steps:</p>
<ol class="simple">
<li><p>Add QuantStub and DeQuantStub for all quantizable ops.</p></li>
<li><p>Fuse possible patterns, such as Conv + Relu and Conv + BN + Relu.</p></li>
</ol>
<p>Torchvision provide quantized_model, so we didn’t do these steps above for all torchvision models. Please refer <a class="reference external" href="https://github.com/pytorch/vision/tree/master/torchvision/models/quantization">torchvision</a></p>
<p>The related code please refer to examples/pytorch/image_recognition/imagenet/cpu/ptq/main.py.</p>
</div>
<div class="section" id="code-update">
<h2>Code Update<a class="headerlink" href="#code-update" title="Permalink to this headline">¶</a></h2>
<p>After prepare step is done, we just need update main.py like below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">fuse_model</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">(</span><span class="s2">&quot;./conf.yaml&quot;</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">q_model</span> <span class="o">=</span> <span class="n">quantizer</span><span class="p">()</span>
</pre></div>
</div>
<p>The quantizer() function will return a best quantized model during timeout constrain.</p>
</div>
<div class="section" id="dump-tensors-for-debug">
<h2>Dump tensors for debug<a class="headerlink" href="#dump-tensors-for-debug" title="Permalink to this headline">¶</a></h2>
<p>LPOT can dump every layer output tensor which you specify in evaluation. You just need to add some setting to yaml configure file as below:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">tensorboard</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<p>The default value of “tensorboard” is “off”.</p>
<p>For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sh run_tuning_dump_tensor.sh --topology<span class="o">=</span>resnet18 --dataset_location<span class="o">=</span>&lt;Dataset&gt;
</pre></div>
</div>
<p>A “./runs” folder will be generated, for example</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ls runs/eval/
tune_0_acc0.73  tune_1_acc0.71 tune_2_acc0.72
</pre></div>
</div>
<p>“tune_0_acc0.73” means FP32 baseline is accuracy 0.73, and the best tune result is tune_2 with accuracy 0.72. You may want to compare them in tensorboard. It will demonstrate the output tensor and weight of each op in “Histogram”, you can also find the tune config of each tuning run in “Text”:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard --bind_all --logdir_spec baseline:./runs/eval/tune_0_acc0.73,tune_2:././runs/eval/tune_2_acc0.72
</pre></div>
</div>
</div>
<div class="section" id="tuning-with-intel-pytorch-extension">
<h2>Tuning With Intel PyTorch Extension<a class="headerlink" href="#tuning-with-intel-pytorch-extension" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Write Yaml Config File</p></li>
</ol>
<p>Add ‘backend’ field to Yaml Configure and the same for other fields.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span>  <span class="nt">model</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">imagenet</span>
  <span class="nt">framework</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pytorch_ipex</span> 
</pre></div>
</div>
<ol class="simple">
<li><p>Tuning With LPOT</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
  <span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">(</span><span class="s2">&quot;./conf_ipex.yaml&quot;</span><span class="p">)</span>
  <span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
  <span class="n">lpot_model</span> <span class="o">=</span> <span class="n">quantizer</span><span class="p">()</span>
  <span class="n">lpot_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;Path_to_save_configure_file&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ol class="simple">
<li><p>Saving and Run ipex model</p></li>
</ol>
<ul class="simple">
<li><p>Saving model</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="n">lpot_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;Path_to_save_configure_file&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, lpot_model is the result of LPOT tuning. It is LPOT.model class, so it has “save” API.</p>
<ul class="simple">
<li><p>Run ipex model:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">intel_pytorch_extension</span> <span class="kn">as</span> <span class="nn">ipex</span> 
<span class="n">model</span>                 <span class="c1"># fp32 model</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ipex</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">new_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">new_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ipex</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">))</span>
<span class="n">ipex_config_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">tuned_checkpoint</span><span class="p">),</span>
                                <span class="s2">&quot;best_configure.json&quot;</span><span class="p">)</span>
<span class="n">conf</span> <span class="o">=</span> <span class="n">ipex</span><span class="o">.</span><span class="n">AmpConf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">,</span> <span class="n">configure_file</span><span class="o">=</span><span class="n">ipex_config_path</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">ipex</span><span class="o">.</span><span class="n">AutoMixPrecision</span><span class="p">(</span><span class="n">conf</span><span class="p">,</span> <span class="n">running_mode</span><span class="o">=</span><span class="s1">&#39;inference&#39;</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">new_model</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">ipex</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Intel® LPOT.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>