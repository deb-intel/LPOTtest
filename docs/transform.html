

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Transform &mdash; Intel® Low Precision Optimization Tool  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Dataset" href="dataset.html" />
    <link rel="prev" title="Developer Documentation" href="doclist.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Intel® Low Precision Optimization Tool
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../welcome.html">Introduction to Intel LPOT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-documentation/api-introduction.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples_readme.html">Examples</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="doclist.html">Developer Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="doclist.html#getting-started">Getting Started</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../api-documentation/api-introduction.html">API Documentation</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Transform</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#transform-support-list">Transform support list</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dataset.html">Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="metric.html">Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples_readme.html">Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="ux.html">LPOT UX</a></li>
<li class="toctree-l3"><a class="reference external" href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Intel oneAPI AI Analytics Toolkit Get Started Guide</a></li>
<li class="toctree-l3"><a class="reference external" href="https://github.com/oneapi-src/oneAPI-samples/tree/master/AI-and-Analytics">AI and Analytics Samples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="doclist.html#deep-dive">Deep Dive</a></li>
<li class="toctree-l2"><a class="reference internal" href="doclist.html#advanced-topics">Advanced Topics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../releases_info.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../security_policy.html">Security Policy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Low Precision Optimization Tool</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="doclist.html">Developer Documentation</a> &raquo;</li>
        
      <li>Transform</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/docs/transform.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="transform">
<h1>Transform<a class="headerlink" href="#transform" title="Permalink to this headline">¶</a></h1>
<p>LPOT supports builtin preprocessing methods on diffrent framework backend. Pleaes refer to ‘examples/helloworld/tf_example1’ about how to config a transform in dataloader.</p>
<div class="section" id="transform-support-list">
<h2>Transform support list<a class="headerlink" href="#transform-support-list" title="Permalink to this headline">¶</a></h2>
<div class="section" id="tensorflow">
<h3>TensorFlow<a class="headerlink" href="#tensorflow" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Transform</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage(In yaml file)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Resize(size, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Resize the input image to the given size</td>
<td align="left">Resize: <br> &ensp;&ensp; size: 256 <br> &ensp;&ensp;  interpolation: bilinear</td>
</tr>
<tr>
<td align="left">CenterCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crops the given image at the center to the given size</td>
<td align="left">CenterCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10</td>
</tr>
<tr>
<td align="left">RandomResizedCrop(size, scale, ratio, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>scale</strong> (tuple or list, default=(0.08, 1.0)):range of size of the origin size cropped <br> <strong>ratio</strong> (tuple or list, default=(3. / 4., 4. / 3.)): range of aspect ratio of the origin aspect ratio cropped <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest'</td>
<td align="left">Crop the given image to random size and aspect ratio</td>
<td align="left">RandomResizedCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10 <br> &ensp;&ensp; scale: [0.08, 1.0] <br> &ensp;&ensp; ratio: [3. / 4., 4. / 3.] <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Normalize(mean, std)</td>
<td align="left"><strong>mean</strong> (list, default=[0.0]):means for each channel, if len(mean)=1, mean will be broadcasted to each channel, otherwise its length should be same with the length of image shape <br> <strong>std</strong> (list, default=[1.0]):stds for each channel, if len(std)=1, std will be broadcasted to each channel, otherwise its length should be same with the length of image shape</td>
<td align="left">Normalize a image with mean and standard deviation</td>
<td align="left">Normalize: <br> &ensp;&ensp; mean: [0.0, 0.0, 0.0] <br> &ensp;&ensp; std: [1.0, 1.0, 1.0]</td>
</tr>
<tr>
<td align="left">RandomCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crop the image at a random location to the given size</td>
<td align="left">RandomCrop: <br> &ensp;&ensp; size: [10, 10] # size: 10</td>
</tr>
<tr>
<td align="left">Compose(transform_list)</td>
<td align="left"><strong>transform_list</strong> (list of Transform objects):  list of transforms to compose</td>
<td align="left">Composes several transforms together</td>
<td align="left">If user uses yaml file to configure transforms, LPOT will automatic call Compose to group other transforms. <br> <strong>In user code:</strong> <br> from lpot.experimental.data  import TRANSFORMS <br> preprocess = TRANSFORMS(framework, 'preprocess') <br> resize = preprocess["Resize"] (*<em>args) <br> normalize = preprocess["Normalize"] (*</em>args) <br> compose = preprocess["Compose"] ([resize, normalize]) <br> sample = compose(sample) <br> # sample: image, label</td>
</tr>
<tr>
<td align="left">CropResize(x, y, width, height, size, interpolation)</td>
<td align="left"><strong>x</strong> (int):Left boundary of the cropping area <br> <strong>y</strong> (int):Top boundary of the cropping area <br> <strong>width</strong> (int):Width of the cropping area <br> <strong>height</strong> (int):Height of the cropping area <br> <strong>size</strong> (list or int): resize to new size after cropping <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest' and 'bicubic'</td>
<td align="left">Crop the input image with given location and resize it</td>
<td align="left">CropResize: <br> &ensp;&ensp; x: 0 <br> &ensp;&ensp; y: 5 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; size: [100, 100] # or size: 100 <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">RandomHorizontalFlip()</td>
<td align="left">None</td>
<td align="left">Horizontally flip the given image randomly</td>
<td align="left">RandomHorizontalFlip: {}</td>
</tr>
<tr>
<td align="left">RandomVerticalFlip()</td>
<td align="left">None</td>
<td align="left">Vertically flip the given image randomly</td>
<td align="left">RandomVerticalFlip: {}</td>
</tr>
<tr>
<td align="left">DecodeImage()</td>
<td align="left">None</td>
<td align="left">Decode a JPEG-encoded image to a uint8 tensor</td>
<td align="left">DecodeImage: {}</td>
</tr>
<tr>
<td align="left">EncodeJped()</td>
<td align="left">None</td>
<td align="left">Encode image to a  Tensor of type string</td>
<td align="left">EncodeJped: {}</td>
</tr>
<tr>
<td align="left">Transpose(perm)</td>
<td align="left"><strong>perm</strong> (list): A permutation of the dimensions of input image</td>
<td align="left">Transpose image according perm</td>
<td align="left">Transpose: <br> &ensp;&ensp; perm: [1, 2, 0]</td>
</tr>
<tr>
<td align="left">CropToBoundingBox(offset_height, offset_width, target_height, target_width)</td>
<td align="left"><strong>offset_height</strong> (int): Vertical coordinate of the top-left corner of the result in the input <br> <strong>offset_width</strong> (int): Horizontal coordinate of the top-left corner of the result in the input <br> <strong>target_height</strong> (int): Height of the result <br> <strong>target_width</strong> (int): Width of the result</td>
<td align="left">Crops an image to a specified bounding box</td>
<td align="left">CropToBoundingBox: <br> &ensp;&ensp; offset_height: 10 <br> &ensp;&ensp; offset_width: 10 <br> &ensp;&ensp; target_height: 224 <br> &ensp;&ensp; 224</td>
</tr>
<tr>
<td align="left">Cast(dtype)</td>
<td align="left"><strong>dtype</strong> (str, default='float32'): A dtype to convert image to</td>
<td align="left">Convert image to given dtype</td>
<td align="left">Cast: <br> &ensp;&ensp; dtype: float32</td>
</tr>
<tr>
<td align="left">ToArray()</td>
<td align="left">None</td>
<td align="left">Convert PIL Image to numpy array</td>
<td align="left">ToArray: {}</td>
</tr>
<tr>
<td align="left">Rescale()</td>
<td align="left">None</td>
<td align="left">Scale the values of image to [0,1]</td>
<td align="left">Rescale: {}</td>
</tr>
<tr>
<td align="left">AlignImageChannel(dim)</td>
<td align="left"><strong>dim</strong> (int): The channel number of result image</td>
<td align="left">Align image channel, now just support [H,W]-&gt;[H,W,dim], [H,W,4]-&gt;[H,W,3] and [H,W,3]-&gt;[H,W]</td>
<td align="left">AlignImageChannel: <br> &ensp;&ensp; dim: 3</td>
</tr>
<tr>
<td align="left">ParseDecodeImagenet()</td>
<td align="left">None</td>
<td align="left">Parse features in Example proto</td>
<td align="left">ParseDecodeImagenet: {}</td>
</tr>
<tr>
<td align="left">ResizeCropImagenet(height, width, random_crop, resize_side, random_flip_left_right, mean_value, scale)</td>
<td align="left"><strong>height</strong> (int): Height of the result <br> <strong>width</strong> (int): Width of the result <br> <strong>random_crop</strong> (bool, default=False): whether to random crop <br> <strong>resize_side</strong> (int, default=256):desired shape after resize operation <br> <strong>random_flip_left_right</strong> (bool, default=False): whether to random flip left and right <br> <strong>mean_value</strong> (list, default=[0.0,0.0,0.0]):means for each channel <br> <strong>scale</strong> (float, default=1.0):std value</td>
<td align="left">Combination of a series of transforms which is applicable to images in Imagenet</td>
<td align="left">ResizeCropImagenet: <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; random_crop: False <br> &ensp;&ensp; resize_side: 256 <br> &ensp;&ensp; random_flip_left_right: False <br> &ensp;&ensp; mean_value: [123.68, 116.78, 103.94] <br> &ensp;&ensp; scale: 0.017</td>
</tr>
<tr>
<td align="left">QuantizedInput(dtype, scale)</td>
<td align="left"><strong>dtype</strong>(str): desired image dtype, support 'uint8', 'int8' <br> <strong>scale</strong>(float, default=None):scaling ratio of each point in image</td>
<td align="left">Convert the dtype of input to quantize it</td>
<td align="left">QuantizedInput: <br> &ensp;&ensp; dtype: 'uint8'</td>
</tr>
<tr>
<td align="left">LabelShift(label_shift)</td>
<td align="left"><strong>label_shift</strong>(int, default=0): number of label shift</td>
<td align="left">Convert label to label - label_shift</td>
<td align="left">LabelShift: <br> &ensp;&ensp; label_shift: 0</td>
</tr>
<tr>
<td align="left">BilinearImagenet(height, width, central_fraction, mean_value, scale)</td>
<td align="left"><strong>height</strong>(int): Height of the result <br> <strong>width</strong>(int):Width of the result <br> <strong>central_fraction</strong>(float, default=0.875):fraction of size to crop <br> <strong>mean_value</strong>(list, default=[0.0,0.0,0.0]):means for each channel <br> <strong>scale</strong>(float, default=1.0):std value</td>
<td align="left">Combination of a series of transforms which is applicable to images in Imagenet</td>
<td align="left">BilinearImagenet: <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; central_fraction: 0.875 <br> &ensp;&ensp; mean_value: [0.0,0.0,0.0] <br> &ensp;&ensp; scale: 1.0</td>
</tr>
<tr>
<td align="left">SquadV1(label_file, n_best_size, max_seq_length, max_query_length, max_answer_length, do_lower_case, doc_stride)</td>
<td align="left"><strong>label_file</strong> (str): path of label file <br> <strong>vocab_file</strong>(str): path of vocabulary file <br> <strong>n_best_size</strong> (int, default=20): The total number of n-best predictions to generate in the nbest_predictions.json output file <br> <strong>max_seq_length</strong> (int, default=384): The maximum total input sequence length after WordPiece tokenization. Sequences longer than this will be truncated, and sequences shorter, than this will be padded <br> <strong>max_query_length</strong> (int, default=64): The maximum number of tokens for the question. Questions longer than this will be truncated to this length <br> <strong>max_answer_length</strong> (int, default=30): The maximum length of an answer that can be generated. This is needed because the start and end predictions are not conditioned on one another <br> <strong>do_lower_case</strong> (bool, default=True): Whether to lower case the input text. Should be True for uncased models and False for cased models <br> <strong>doc_stride</strong> (int, default=128): When splitting up a long document into chunks, how much stride to take between chunks</td>
<td align="left">Postprocess the predictions of bert on SQuAD</td>
<td align="left">SquadV1 <br> &ensp;&ensp; label_file: /path/to/label_file <br> &ensp;&ensp; n_best_size: 20 <br> &ensp;&ensp; max_seq_length: 384 <br> &ensp;&ensp; max_query_length: 64 <br> &ensp;&ensp; max_answer_length: 30 <br> &ensp;&ensp; do_lower_case: True <br> &ensp;&ensp; doc_stride: True</td>
</tr>
</tbody>
</table></div>
<div class="section" id="pytorch">
<h3>Pytorch<a class="headerlink" href="#pytorch" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Transform</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage(In yaml file)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Resize(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> interpolation(str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Resize the input image to the given size</td>
<td align="left">Resize: <br> &ensp;&ensp; size: 256 <br> &ensp;&ensp;  interpolation: bilinear</td>
</tr>
<tr>
<td align="left">CenterCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crops the given image at the center to the given size</td>
<td align="left">CenterCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10</td>
</tr>
<tr>
<td align="left">RandomResizedCrop(size, scale, ratio, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>scale</strong> (tuple or list, default=(0.08, 1.0)):range of size of the origin size cropped <br> <strong>ratio</strong> (tuple or list, default=(3. / 4., 4. / 3.)): range of aspect ratio of the origin aspect ratio cropped <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Crop the given image to random size and aspect ratio</td>
<td align="left">RandomResizedCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10 <br> &ensp;&ensp; scale: [0.08, 1.0] <br> &ensp;&ensp; ratio: [3. / 4., 4. / 3.] <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Normalize(mean, std)</td>
<td align="left"><strong>mean</strong> (list, default=[0.0]):means for each channel, if len(mean)=1, mean will be broadcasted to each channel, otherwise its length should be same with the length of image shape <br> <strong>std</strong> (list, default=[1.0]):stds for each channel, if len(std)=1, std will be broadcasted to each channel, otherwise its length should be same with the length of image shape</td>
<td align="left">Normalize a image with mean and standard deviation</td>
<td align="left">Normalize: <br> &ensp;&ensp; mean: [0.0, 0.0, 0.0] <br> &ensp;&ensp; std: [1.0, 1.0, 1.0]</td>
</tr>
<tr>
<td align="left">RandomCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crop the image at a random location to the given size</td>
<td align="left">RandomCrop: <br> &ensp;&ensp; size: [10, 10] # size: 10</td>
</tr>
<tr>
<td align="left">Compose(transform_list)</td>
<td align="left"><strong>transform_list</strong> (list of Transform objects):  list of transforms to compose</td>
<td align="left">Composes several transforms together</td>
<td align="left">If user uses yaml file to configure transforms, LPOT will automatic call Compose to group other transforms. <br> <strong>In user code:</strong> <br> from lpot.experimental.data  import TRANSFORMS <br> preprocess = TRANSFORMS(framework, 'preprocess') <br> resize = preprocess["Resize"] (*<em>args) <br> normalize = preprocess["Normalize"] (*</em>args) <br> compose = preprocess["Compose"] ([resize, normalize]) <br> sample = compose(sample) <br> # sample: image, label</td>
</tr>
<tr>
<td align="left">RandomHorizontalFlip()</td>
<td align="left">None</td>
<td align="left">Horizontally flip the given image randomly</td>
<td align="left">RandomHorizontalFlip: {}</td>
</tr>
<tr>
<td align="left">RandomVerticalFlip()</td>
<td align="left">None</td>
<td align="left">Vertically flip the given image randomly</td>
<td align="left">RandomVerticalFlip: {}</td>
</tr>
<tr>
<td align="left">Transpose(perm)</td>
<td align="left"><strong>perm</strong> (list): A permutation of the dimensions of input image</td>
<td align="left">Transpose image according perm</td>
<td align="left">Transpose: <br> &ensp;&ensp; perm: [1, 2, 0]</td>
</tr>
<tr>
<td align="left">CropToBoundingBox(offset_height, offset_width, target_height, target_width)</td>
<td align="left"><strong>offset_height</strong> (int): Vertical coordinate of the top-left corner of the result in the input <br> <strong>offset_width</strong> (int): Horizontal coordinate of the top-left corner of the result in the input <br> <strong>target_height</strong> (int): Height of the result <br> <strong>target_width</strong> (int): Width of the result</td>
<td align="left">Crops an image to a specified bounding box</td>
<td align="left">CropToBoundingBox: <br> &ensp;&ensp; offset_height: 10 <br> &ensp;&ensp; offset_width: 10 <br> &ensp;&ensp; target_height: 224 <br> &ensp;&ensp; 224</td>
</tr>
<tr>
<td align="left">ToTensor()</td>
<td align="left">None</td>
<td align="left">Convert a PIL Image or numpy.ndarray to tensor</td>
<td align="left">ToTensor: {}</td>
</tr>
<tr>
<td align="left">ToPILImage()</td>
<td align="left">None</td>
<td align="left">Convert a tensor or an ndarray to PIL Image</td>
<td align="left">ToPILImage: {}</td>
</tr>
<tr>
<td align="left">Pad(padding, fill, padding_mode)</td>
<td align="left"><strong>padding</strong> (int or tuple or list): Padding on each border <br> <strong>fill</strong> (int or str or tuple): Pixel fill value for constant fill. Default is 0 <br> <strong>padding_mode</strong> (str): Type of padding. Should be: constant, edge, reflect or symmetric. Default is constant</td>
<td align="left">Pad the given image on all sides with the given “pad” value</td>
<td align="left">Pad: <br> &ensp;&ensp; padding: 0 <br> &ensp;&ensp; fill: 0 <br> &ensp;&ensp; padding_mode: constant</td>
</tr>
<tr>
<td align="left">ColorJitter(brightness, contrast, saturation, hue)</td>
<td align="left"><strong>brightness</strong> (float or tuple of python:float (min, max)): How much to jitter brightness. Default is 0 <br> <strong>contrast</strong> (float or tuple of python:float (min, max)): How much to jitter contrast. Default is 0 <br> <strong>saturation</strong> (float or tuple of python:float (min, max)): How much to jitter saturation. Default is 0 <br> <strong>hue</strong> (float or tuple of python:float (min, max)): How much to jitter hue. Default is 0</td>
<td align="left">Randomly change the brightness, contrast, saturation and hue of an image</td>
<td align="left">ColorJitter: <br> &ensp;&ensp; brightness: 0 <br> &ensp;&ensp; contrast: 0 <br> &ensp;&ensp; saturation: 0 <br> &ensp;&ensp; hue: 0</td>
</tr>
<tr>
<td align="left">ToArray()</td>
<td align="left">None</td>
<td align="left">Convert PIL Image to numpy array</td>
<td align="left">ToArray: {}</td>
</tr>
<tr>
<td align="left">CropResize(x, y, width, height, size, interpolation)</td>
<td align="left"><strong>x</strong> (int):Left boundary of the cropping area <br> <strong>y</strong> (int):Top boundary of the cropping area <br> <strong>width</strong> (int):Width of the cropping area <br> <strong>height</strong> (int):Height of the cropping area <br> <strong>size</strong> (list or int): resize to new size after cropping <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Crop the input image with given location and resize it</td>
<td align="left">CropResize: <br> &ensp;&ensp; x: 0 <br> &ensp;&ensp; y: 5 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; size: [100, 100] # or size: 100 <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Cast(dtype)</td>
<td align="left"><strong>dtype</strong> (str, default ='float32') :The target data type</td>
<td align="left">Convert image to given dtype</td>
<td align="left">Cast: <br> &ensp;&ensp; dtype: float32</td>
</tr>
<tr>
<td align="left">AlignImageChannel(dim)</td>
<td align="left"><strong>dim</strong> (int): The channel number of result image</td>
<td align="left">Align image channel, now just support [H,W,4]-&gt;[H,W,3] and [H,W,3]-&gt;[H,W], input image must be PIL Image</td>
<td align="left">AlignImageChannel: <br> &ensp;&ensp; dim: 3</td>
</tr>
</tbody>
</table></div>
<div class="section" id="mxnet">
<h3>MXNet<a class="headerlink" href="#mxnet" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Transform</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage(In yaml file)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Resize(size, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Resize the input image to the given size</td>
<td align="left">Resize: <br> &ensp;&ensp; size: 256 <br> &ensp;&ensp;  interpolation: bilinear</td>
</tr>
<tr>
<td align="left">CenterCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crops the given image at the center to the given size</td>
<td align="left">CenterCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10</td>
</tr>
<tr>
<td align="left">RandomResizedCrop(size, scale, ratio, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>scale</strong> (tuple or list, default=(0.08, 1.0)):range of size of the origin size cropped <br> <strong>ratio</strong> (tuple or list, default=(3. / 4., 4. / 3.)): range of aspect ratio of the origin aspect ratio cropped <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Crop the given image to random size and aspect ratio</td>
<td align="left">RandomResizedCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10 <br> &ensp;&ensp; scale: [0.08, 1.0] <br> &ensp;&ensp; ratio: [3. / 4., 4. / 3.] <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Normalize(mean, std)</td>
<td align="left"><strong>mean</strong> (list, default=[0.0]):means for each channel, if len(mean)=1, mean will be broadcasted to each channel, otherwise its length should be same with the length of image shape <br> <strong>std</strong> (list, default=[1.0]):stds for each channel, if len(std)=1, std will be broadcasted to each channel, otherwise its length should be same with the length of image shape</td>
<td align="left">Normalize a image with mean and standard deviation</td>
<td align="left">Normalize: <br> &ensp;&ensp; mean: [0.0, 0.0, 0.0] <br> &ensp;&ensp; std: [1.0, 1.0, 1.0]</td>
</tr>
<tr>
<td align="left">RandomCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crop the image at a random location to the given size</td>
<td align="left">RandomCrop: <br> &ensp;&ensp; size: [10, 10] # size: 10</td>
</tr>
<tr>
<td align="left">Compose(transform_list)</td>
<td align="left"><strong>transform_list</strong> (list of Transform objects):  list of transforms to compose</td>
<td align="left">Composes several transforms together</td>
<td align="left">If user uses yaml file to configure transforms, LPOT will automatic call Compose to group other transforms. <br> <strong>In user code:</strong> <br> from lpot.experimental.data  import TRANSFORMS <br> preprocess = TRANSFORMS(framework, 'preprocess') <br> resize = preprocess["Resize"] (*<em>args) <br> normalize = preprocess["Normalize"] (*</em>args) <br> compose = preprocess["Compose"] ([resize, normalize]) <br> sample = compose(sample) <br> # sample: image, label</td>
</tr>
<tr>
<td align="left">CropResize(x, y, width, height, size, interpolation)</td>
<td align="left"><strong>x</strong> (int):Left boundary of the cropping area <br> <strong>y</strong> (int):Top boundary of the cropping area <br> <strong>width</strong> (int):Width of the cropping area <br> <strong>height</strong> (int):Height of the cropping area <br> <strong>size</strong> (list or int): resize to new size after cropping <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Crop the input image with given location and resize it</td>
<td align="left">CropResize: <br> &ensp;&ensp; x: 0 <br> &ensp;&ensp; y: 5 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; size: [100, 100] # or size: 100 <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">RandomHorizontalFlip()</td>
<td align="left">None</td>
<td align="left">Horizontally flip the given image randomly</td>
<td align="left">RandomHorizontalFlip: {}</td>
</tr>
<tr>
<td align="left">RandomVerticalFlip()</td>
<td align="left">None</td>
<td align="left">Vertically flip the given image randomly</td>
<td align="left">RandomVerticalFlip: {}</td>
</tr>
<tr>
<td align="left">CropToBoundingBox(offset_height, offset_width, target_height, target_width)</td>
<td align="left"><strong>offset_height</strong> (int): Vertical coordinate of the top-left corner of the result in the input <br> <strong>offset_width</strong> (int): Horizontal coordinate of the top-left corner of the result in the input <br> <strong>target_height</strong> (int): Height of the result <br> <strong>target_width</strong> (int): Width of the result</td>
<td align="left">Crops an image to a specified bounding box</td>
<td align="left">CropToBoundingBox: <br> &ensp;&ensp; offset_height: 10 <br> &ensp;&ensp; offset_width: 10 <br> &ensp;&ensp; target_height: 224 <br> &ensp;&ensp; 224</td>
</tr>
<tr>
<td align="left">ToArray()</td>
<td align="left">None</td>
<td align="left">Convert NDArray to numpy array</td>
<td align="left">ToArray: {}</td>
</tr>
<tr>
<td align="left">ToTensor()</td>
<td align="left">None</td>
<td align="left">Converts an image NDArray or batch of image NDArray to a tensor NDArray</td>
<td align="left">ToTensor: {}</td>
</tr>
<tr>
<td align="left">Cast(dtype)</td>
<td align="left"><strong>dtype</strong> (str, default ='float32') :The target data type</td>
<td align="left">Convert image to given dtype</td>
<td align="left">Cast: <br> &ensp;&ensp; dtype: float32</td>
</tr>
<tr>
<td align="left">Transpose(perm)</td>
<td align="left"><strong>perm</strong> (list): A permutation of the dimensions of input image</td>
<td align="left">Transpose image according perm</td>
<td align="left">Transpose: <br> &ensp;&ensp; perm: [1, 2, 0]</td>
</tr>
<tr>
<td align="left">AlignImageChannel(dim)</td>
<td align="left"><strong>dim</strong> (int): The channel number of result image</td>
<td align="left">Align image channel, now just support [H,W]-&gt;[H,W,dim], [H,W,4]-&gt;[H,W,3] and [H,W,3]-&gt;[H,W]</td>
<td align="left">AlignImageChannel: <br> &ensp;&ensp; dim: 3</td>
</tr>
<tr>
<td align="left">ToNDArray()</td>
<td align="left">None</td>
<td align="left">Convert np.array to NDArray</td>
<td align="left">ToNDArray: {}</td>
</tr>
</tbody>
</table></div>
<div class="section" id="onnxrt">
<h3>ONNXRT<a class="headerlink" href="#onnxrt" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Type</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage(In yaml file)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Resize(size, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest', 'bicubic'</td>
<td align="left">Resize the input image to the given size</td>
<td align="left">Resize: <br> &ensp;&ensp; size: 256 <br> &ensp;&ensp;  interpolation: bilinear</td>
</tr>
<tr>
<td align="left">CenterCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crops the given image at the center to the given size</td>
<td align="left">CenterCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10</td>
</tr>
<tr>
<td align="left">RandomResizedCrop(size, scale, ratio, interpolation)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result <br> <strong>scale</strong> (tuple or list, default=(0.08, 1.0)):range of size of the origin size cropped <br> <strong>ratio</strong> (tuple or list, default=(3. / 4., 4. / 3.)): range of aspect ratio of the origin aspect ratio cropped <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest'</td>
<td align="left">Crop the given image to random size and aspect ratio</td>
<td align="left">RandomResizedCrop: <br> &ensp;&ensp; size: [10, 10] # or size: 10 <br> &ensp;&ensp; scale: [0.08, 1.0] <br> &ensp;&ensp; ratio: [3. / 4., 4. / 3.] <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">Normalize(mean, std)</td>
<td align="left"><strong>mean</strong> (list, default=[0.0]):means for each channel, if len(mean)=1, mean will be broadcasted to each channel, otherwise its length should be same with the length of image shape <br> <strong>std</strong> (list, default=[1.0]):stds for each channel, if len(std)=1, std will be broadcasted to each channel, otherwise its length should be same with the length of image shape</td>
<td align="left">Normalize a image with mean and standard deviation</td>
<td align="left">Normalize: <br> &ensp;&ensp; mean: [0.0, 0.0, 0.0] <br> &ensp;&ensp; std: [1.0, 1.0, 1.0]</td>
</tr>
<tr>
<td align="left">RandomCrop(size)</td>
<td align="left"><strong>size</strong> (list or int): Size of the result</td>
<td align="left">Crop the image at a random location to the given size</td>
<td align="left">RandomCrop: <br> &ensp;&ensp; size: [10, 10] # size: 10</td>
</tr>
<tr>
<td align="left">Compose(transform_list)</td>
<td align="left"><strong>transform_list</strong> (list of Transform objects):  list of transforms to compose</td>
<td align="left">Composes several transforms together</td>
<td align="left">If user uses yaml file to configure transforms, LPOT will automatic call Compose to group other transforms. <br> <strong>In user code:</strong> <br> from lpot.experimental.data  import TRANSFORMS <br> preprocess = TRANSFORMS(framework, 'preprocess') <br> resize = preprocess["Resize"] (*<em>args) <br> normalize = preprocess["Normalize"] (*</em>args) <br> compose = preprocess["Compose"] ([resize, normalize]) <br> sample = compose(sample) <br> # sample: image, label</td>
</tr>
<tr>
<td align="left">CropResize(x, y, width, height, size, interpolation)</td>
<td align="left"><strong>x</strong> (int):Left boundary of the cropping area <br> <strong>y</strong> (int):Top boundary of the cropping area <br> <strong>width</strong> (int):Width of the cropping area <br> <strong>height</strong> (int):Height of the cropping area <br> <strong>size</strong> (list or int): resize to new size after cropping <br> <strong>interpolation</strong> (str, default='bilinear'):Desired interpolation type, support 'bilinear', 'nearest'</td>
<td align="left">Crop the input image with given location and resize it</td>
<td align="left">CropResize: <br> &ensp;&ensp; x: 0 <br> &ensp;&ensp; y: 5 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; size: [100, 100] # or size: 100 <br> &ensp;&ensp; interpolation: bilinear</td>
</tr>
<tr>
<td align="left">RandomHorizontalFlip()</td>
<td align="left">None</td>
<td align="left">Horizontally flip the given image randomly</td>
<td align="left">RandomHorizontalFlip: {}</td>
</tr>
<tr>
<td align="left">RandomVerticalFlip()</td>
<td align="left">None</td>
<td align="left">Vertically flip the given image randomly</td>
<td align="left">RandomVerticalFlip: {}</td>
</tr>
<tr>
<td align="left">CropToBoundingBox(offset_height, offset_width, target_height, target_width)</td>
<td align="left"><strong>offset_height</strong> (int): Vertical coordinate of the top-left corner of the result in the input <br> <strong>offset_width</strong> (int): Horizontal coordinate of the top-left corner of the result in the input <br> <strong>target_height</strong> (int): Height of the result <br> <strong>target_width</strong> (int): Width of the result</td>
<td align="left">Crops an image to a specified bounding box</td>
<td align="left">CropToBoundingBox: <br> &ensp;&ensp; offset_height: 10 <br> &ensp;&ensp; offset_width: 10 <br> &ensp;&ensp; target_height: 224 <br> &ensp;&ensp; 224</td>
</tr>
<tr>
<td align="left">ToArray()</td>
<td align="left">None</td>
<td align="left">Convert PIL Image to numpy array</td>
<td align="left">ToArray: {}</td>
</tr>
<tr>
<td align="left">Rescale()</td>
<td align="left">None</td>
<td align="left">Scale the values of image to [0,1]</td>
<td align="left">Rescale: {}</td>
</tr>
<tr>
<td align="left">AlignImageChannel(dim)</td>
<td align="left"><strong>dim</strong> (int): The channel number of result image</td>
<td align="left">Align image channel, now just support [H,W]-&gt;[H,W,dim], [H,W,4]-&gt;[H,W,3] and [H,W,3]-&gt;[H,W]</td>
<td align="left">AlignImageChannel: <br> &ensp;&ensp; dim: 3</td>
</tr>
<tr>
<td align="left">ResizeCropImagenet(height, width, random_crop, resize_side, random_flip_left_right, mean_value, scale)</td>
<td align="left"><strong>height</strong> (int): Height of the result <br> <strong>width</strong> (int): Width of the result <br> <strong>random_crop</strong> (bool, default=False): whether to random crop <br> <strong>resize_side</strong> (int, default=256):desired shape after resize operation <br> <strong>random_flip_left_right</strong> (bool, default=False): whether to random flip left and right <br> <strong>mean_value</strong> (list, default=[0.0,0.0,0.0]):mean for each channel <br> <strong>scale</strong> (float, default=1.0):std value</td>
<td align="left">Combination of a series of transforms which is applicasble to images in Imagenet</td>
<td align="left">ResizeCropImagenet: <br> &ensp;&ensp; height: 224 <br> &ensp;&ensp; width: 224 <br> &ensp;&ensp; random_crop: False <br> &ensp;&ensp; resize_side: 256 <br> &ensp;&ensp; random_flip_left_right: False <br> &ensp;&ensp; mean_value: [123.68, 116.78, 103.94] <br> &ensp;&ensp; scale: 0.017</td>
</tr>
<tr>
<td align="left">Cast(dtype)</td>
<td align="left"><strong>dtype</strong> (str, default ='float32') :The target data type</td>
<td align="left">Convert image to given dtype</td>
<td align="left">Cast: <br> &ensp;&ensp; dtype: float32</td>
</tr>
</tbody>
</table></div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="dataset.html" class="btn btn-neutral float-right" title="Dataset" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="doclist.html" class="btn btn-neutral float-left" title="Developer Documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Intel® LPOT.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>